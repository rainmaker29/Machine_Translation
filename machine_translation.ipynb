{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1J2xLa0urtv8nWTJKad4gQzU7lDGpUxUy",
      "authorship_tag": "ABX9TyO33SQgsIYA7FbETVWSsp96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainmaker29/Machine_Translation/blob/master/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHozEwdx1_x1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b93c48ec-08b1-42df-f7c3-5d607a88bb01"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU,LSTM,Input,Dense,TimeDistributed,Activation,RepeatVector,Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf1WcFq1-LEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "e35faea4-bc4e-4960-d27a-0614bd220166"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13888284727533729026\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 13625631050519182016\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 16632098643805252552\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 7304675328\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 443494970392580986\n",
            "physical_device_desc: \"device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5eliQcQ-WwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def load_data(path):\n",
        "  input_file= os.path.join(path)\n",
        "  with open(input_file,\"r\") as f:\n",
        "    data = f.read()\n",
        "\n",
        "  return data.split(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC0Iud-F-uX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_sentences = load_data(\"/content/drive/My Drive/machine_translation/small_vocab_en\")\n",
        "french_sentences = load_data(\"/content/drive/My Drive/machine_translation/small_vocab_fr\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVa73_y5_Eqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "055cbb51-d131-44e7-8de9-b280a92f494e"
      },
      "source": [
        "print(english_sentences[0])\n",
        "print(french_sentences[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blk3afqH_oof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "91256bdc-927d-4a86-a80c-4571d043ff5b"
      },
      "source": [
        "english_words = [word for sentence in english_sentences\n",
        "                                     for word in sentence.split()]\n",
        "\n",
        "french_words = [word for sentence in french_sentences\n",
        "                                     for word in sentence.split()]\n",
        "\n",
        "number_of_eng = collections.Counter(english_words)\n",
        "number_of_fr = collections.Counter(french_words)\n",
        "\n",
        "print(f\"English words {len(english_words)}\")\n",
        "print(f\"French words {len(french_words)}\")\n",
        "\n",
        "print(f\"Unique english words {len(number_of_eng)}\")\n",
        "print(f\"Unique english words {len(number_of_fr)}\")\n",
        "\n",
        "print(f\"10 most common english : {list(zip(*number_of_eng.most_common(10)))[0]}\")\n",
        "print(f\"10 most common french: {list(zip(*number_of_fr.most_common(10)))[0]}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English words 1823250\n",
            "French words 1961295\n",
            "Unique english words 227\n",
            "Unique english words 355\n",
            "10 most common english : ('is', ',', '.', 'in', 'it', 'during', 'the', 'but', 'and', 'sometimes')\n",
            "10 most common french: ('est', '.', ',', 'en', 'il', 'les', 'mais', 'et', 'la', 'parfois')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57VnCnGPBYrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(x):\n",
        "  t = Tokenizer()\n",
        "  t.fit_on_texts(x)\n",
        "  return t.texts_to_sequences(x), t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uw35swtC1pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(x,length=None):\n",
        "  if not length:\n",
        "    length = max([len(sent) for sent in x])\n",
        "  return pad_sequences(x,maxlen=length,padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5klOoYQDV5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  preprocess_x, x_tk = tokenize(x)\n",
        "  preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "  preprocess_x = pad(preprocess_x)\n",
        "  preprocess_y = pad(preprocess_y)\n",
        "\n",
        "  # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "  preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "  return preprocess_x, preprocess_y, x_tk, y_tk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSnOqC2nDmYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a1d54ffc-84f0-4f8d-9acc-2f868e636c7d"
      },
      "source": [
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
        "    preprocess(english_sentences, french_sentences)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 15\n",
            "Max French sentence length: 21\n",
            "English vocabulary size: 199\n",
            "French vocabulary size: 344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ3zUngRDujM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<PAD>'\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNZ8VnISEKrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "  inp = Input(shape=(input_shape[1],))\n",
        "  embed = Embedding(output_dim=100, input_dim=english_vocab_size, input_length=input_shape[1])(inp) # (max_length, 100)\n",
        "    \n",
        "  # Encoder\n",
        "  bd_encoded = Bidirectional(GRU(512))(embed) \n",
        "  dense_encoded = Dense(128, activation='relu')(bd_encoded) \n",
        "  decoding_layer = RepeatVector(output_sequence_length)(dense_encoded)\n",
        "    \n",
        "  # Decoder\n",
        "  decoded_gru = Bidirectional(GRU(512, return_sequences=True))(decoding_layer)\n",
        "  preds = TimeDistributed(Dense(french_vocab_size,activation='softmax'))(decoded_gru)\n",
        "    \n",
        "  model = Model(inputs=inp, outputs=preds)\n",
        "  model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(0.005),\n",
        "                  metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp9F8kdmE56i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d633291-91b5-4dc7-be5a-309a65c56040"
      },
      "source": [
        "def final_predictions(x, y, x_tk, y_tk):\n",
        "\n",
        "    model = network(x.shape, y.shape[1], len(x_tk.word_index)+1, len(y_tk.word_index))\n",
        "    model.fit(x,y,batch_size=1024, epochs=25,validation_split=0.2)\n",
        "\n",
        "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
        "    y_id_to_word[0] = '<PAD>'\n",
        "\n",
        "    sentence = 'he saw a old yellow truck'\n",
        "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
        "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
        "    sentences = np.array([sentence[0], x[0]])\n",
        "    predictions = model.predict(sentences, len(sentences))\n",
        "\n",
        "    print('Sample 1:')\n",
        "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
        "    print('Il a vu un vieux camion jaune')\n",
        "    print('Sample 2:')\n",
        "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
        "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
        "\n",
        "\n",
        "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/25\n",
            "110288/110288 [==============================] - 46s 414us/step - loss: 2.1743 - accuracy: 0.5159 - val_loss: nan - val_accuracy: 0.6081\n",
            "Epoch 2/25\n",
            "110288/110288 [==============================] - 43s 386us/step - loss: 1.0910 - accuracy: 0.6925 - val_loss: nan - val_accuracy: 0.7259\n",
            "Epoch 3/25\n",
            "110288/110288 [==============================] - 42s 382us/step - loss: 0.7244 - accuracy: 0.7794 - val_loss: nan - val_accuracy: 0.8241\n",
            "Epoch 4/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.4740 - accuracy: 0.8548 - val_loss: nan - val_accuracy: 0.8985\n",
            "Epoch 5/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.2839 - accuracy: 0.9168 - val_loss: nan - val_accuracy: 0.9348\n",
            "Epoch 6/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.1688 - accuracy: 0.9517 - val_loss: nan - val_accuracy: 0.9560\n",
            "Epoch 7/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.1277 - accuracy: 0.9629 - val_loss: nan - val_accuracy: 0.9608\n",
            "Epoch 8/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.1117 - accuracy: 0.9673 - val_loss: nan - val_accuracy: 0.9644\n",
            "Epoch 9/25\n",
            "110288/110288 [==============================] - 42s 383us/step - loss: 0.0901 - accuracy: 0.9735 - val_loss: nan - val_accuracy: 0.9685\n",
            "Epoch 10/25\n",
            "110288/110288 [==============================] - 43s 385us/step - loss: 0.0863 - accuracy: 0.9747 - val_loss: nan - val_accuracy: 0.9713\n",
            "Epoch 11/25\n",
            "110288/110288 [==============================] - 42s 385us/step - loss: 0.0856 - accuracy: 0.9750 - val_loss: nan - val_accuracy: 0.9717\n",
            "Epoch 12/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.0725 - accuracy: 0.9789 - val_loss: nan - val_accuracy: 0.9759\n",
            "Epoch 13/25\n",
            "110288/110288 [==============================] - 42s 380us/step - loss: 0.0683 - accuracy: 0.9803 - val_loss: nan - val_accuracy: 0.9771\n",
            "Epoch 14/25\n",
            "110288/110288 [==============================] - 42s 382us/step - loss: 0.0576 - accuracy: 0.9832 - val_loss: nan - val_accuracy: 0.9783\n",
            "Epoch 15/25\n",
            "110288/110288 [==============================] - 42s 381us/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: nan - val_accuracy: 0.9786\n",
            "Epoch 16/25\n",
            "110288/110288 [==============================] - 42s 379us/step - loss: 0.0460 - accuracy: 0.9869 - val_loss: nan - val_accuracy: 0.9797\n",
            "Epoch 17/25\n",
            "110288/110288 [==============================] - 42s 379us/step - loss: 0.0544 - accuracy: 0.9848 - val_loss: nan - val_accuracy: 0.9750\n",
            "Epoch 18/25\n",
            "110288/110288 [==============================] - 42s 378us/step - loss: 0.0672 - accuracy: 0.9808 - val_loss: nan - val_accuracy: 0.9758\n",
            "Epoch 19/25\n",
            "110288/110288 [==============================] - 42s 379us/step - loss: 0.0543 - accuracy: 0.9848 - val_loss: nan - val_accuracy: 0.9788\n",
            "Epoch 20/25\n",
            "110288/110288 [==============================] - 42s 378us/step - loss: 0.0646 - accuracy: 0.9820 - val_loss: nan - val_accuracy: 0.9595\n",
            "Epoch 21/25\n",
            "110288/110288 [==============================] - 42s 380us/step - loss: 0.0743 - accuracy: 0.9789 - val_loss: nan - val_accuracy: 0.9750\n",
            "Epoch 22/25\n",
            "110288/110288 [==============================] - 42s 380us/step - loss: 0.0469 - accuracy: 0.9871 - val_loss: nan - val_accuracy: 0.9754\n",
            "Epoch 23/25\n",
            "110288/110288 [==============================] - 42s 378us/step - loss: 0.0563 - accuracy: 0.9844 - val_loss: nan - val_accuracy: 0.9764\n",
            "Epoch 24/25\n",
            "110288/110288 [==============================] - 42s 377us/step - loss: 0.0630 - accuracy: 0.9827 - val_loss: nan - val_accuracy: 0.9759\n",
            "Epoch 25/25\n",
            "110288/110288 [==============================] - 41s 376us/step - loss: 0.0492 - accuracy: 0.9866 - val_loss: nan - val_accuracy: 0.9790\n",
            "Sample 1:\n",
            "il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Il a vu un vieux camion jaune\n",
            "Sample 2:\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyRb2s-4FYIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}